{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e18407ad-d618-4a74-847f-5fb6545490f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f09be906-efeb-42b3-9f38-64de91edb591",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_classification.TextClassificationPipeline at 0x10817dc40>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_classifier = pipeline(\"sentiment-analysis\")\n",
    "sentiment_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78372a93-5e5e-4c2c-bc1f-daffe4d488cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_classifier(\n",
    "    inputs = [\n",
    "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "        \"I hate this so much!\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db16dbe-11f8-49dd-a128-cdab859b163d",
   "metadata": {},
   "source": [
    "## Preprocessing with a tokenizer\n",
    "\n",
    "Like other neural networks, Transformer models can’t process raw text directly, so the first step of our pipeline is to convert the text inputs into numbers that the model can make sense of. To do this we use a tokenizer, which will be responsible for:\n",
    "\n",
    "- Splitting the input into words, subwords, or symbols (like punctuation) that are called tokens\n",
    "- Mapping each token to an integer\n",
    "- Adding additional inputs that may be useful to the model\n",
    "\n",
    "All this preprocessing needs to be done in exactly the same way as when the model was pretrained.\n",
    "\n",
    "To do this, we use the `AutoTokenizer` class and its `from_pretrained()` method. Using the `checkpoint` name of our model, it will automatically fetch the data associated with the model’s tokenizer and cache it.\n",
    "\n",
    "Since the default checkpoint of the `sentiment-analysis pipeline` is `distilbert-base-uncased-finetuned-sst-2-english`, we run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ae4a3ed-00f1-4a6c-9e48-36523b5132f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88d8aeb0-31d4-4df8-9f18-a67adb1cc598",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f6e28ab-16b0-4e72-a5c3-72d2b435a42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ca8b8ef3f44ddda4181d2f1ac229cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb13d6458154b978812cae0f46e45c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a506442450eb41978a83247a2b1a9f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DistilBertTokenizerFast(name_or_path='distilbert-base-uncased-finetuned-sst-2-english', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96393fcd-95ee-43c8-9cd4-9ab0bc83092f",
   "metadata": {},
   "source": [
    "Once we have the tokenizer, we can directly pass our sentences to it and we’ll get back a dictionary that’s ready to feed to our model! The only thing left to do is to convert the list of input IDs to tensors.\n",
    "\n",
    "To specify the type of tensors we want to get back (PyTorch, TensorFlow, or plain NumPy), we use the `return_tensors` argument,\n",
    "\n",
    "Here’s what the results look like as PyTorch tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1f5410f-8ff4-4c54-b7bd-114140d6c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint, PrettyPrinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70305785-d9bd-48bd-b7cf-64f66b8be19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_inputs = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "813f6137-c419-47d3-ae93-b25473d7a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_results = tokenizer(\n",
    "    raw_inputs, padding=True, truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8c5511b-693b-4028-bdc4-297e0476ea2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
      "          2607,  2026,  2878,  2166,  1012,   102],\n",
      "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "print(token_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7448aa8a-5d61-4abe-9e3a-c6560daa7ea1",
   "metadata": {},
   "source": [
    "The output itself is a dictionary containing two keys, `input_ids` and `attention_mask`. `input_ids` contains two rows of integers (one for each sentence) that are the unique identifiers of the tokens in each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcec98ec-d66d-4667-aa4d-7e0986874305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
       "          2607,  2026,  2878,  2166,  1012,   102],\n",
       "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_results['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f9e1962-54e3-487a-b16f-ef293132da04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_results['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72be7800-e437-42e4-a28c-ba31de41dd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of sequence \n",
    "len(token_results['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a76906dc-60f5-4262-a64e-4f17a727c9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of tokens per sequence\n",
    "len(token_results['input_ids'][0]), len(token_results['input_ids'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc6c141-0057-4755-b2a9-841de5748521",
   "metadata": {},
   "source": [
    "## Going through the model\n",
    "\n",
    "We can download our pretrained model the same way we did with our tokenizer. Transformers provides an `AutoModel` class which also has a `from_pretrained()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71907c46-3d47-4925-bd81-2c3f071d72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f0d245c-0c40-4911-bfce-ddc3bd350f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c07e3d3d-85ac-455a-b806-c007d14c90be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232d4e9b-3ec2-4ad7-89da-1aa089cf86d5",
   "metadata": {},
   "source": [
    "This architecture contains only the base Transformer module: given some inputs, it outputs what we’ll call `hidden states`, also known as `features`. \n",
    "\n",
    "For each model input, we’ll retrieve a `high-dimensional` vector representing the `contextual understanding of that input by the Transformer model.`\n",
    "\n",
    "While these hidden states can be useful on their own, they’re usually inputs to another part of the model, known as the `head`. \n",
    "\n",
    "**A high-dimensional vector?**\n",
    "\n",
    "The vector output by the Transformer module is usually large. It generally has `three` dimensions:\n",
    "\n",
    "- **Batch size**: The number of sequences processed at a time (2 in our example).\n",
    "\n",
    "- **Sequence length**: The length of the numerical representation of the sequence (16 in our example).\n",
    "\n",
    "- **Hidden size**: The vector dimension of each model input.\n",
    "\n",
    "It is said to be `high dimensional` because of the `last value`. The `hidden size` can be very large (768 is common for smaller models, and in larger models this can reach 3072 or more).\n",
    "\n",
    "We can see this if we feed the inputs we preprocessed to our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90dcc889-eb2b-4b00-a3c9-1b2a1a87702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**token_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae6489c1-502e-4157-8f53-6a66e92b1e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[-0.1798,  0.2333,  0.6321,  ..., -0.3017,  0.5008,  0.1481],\n",
       "         [ 0.2758,  0.6497,  0.3200,  ..., -0.0760,  0.5136,  0.1329],\n",
       "         [ 0.9046,  0.0985,  0.2950,  ...,  0.3352, -0.1407, -0.6464],\n",
       "         ...,\n",
       "         [ 0.1466,  0.5661,  0.3235,  ..., -0.3376,  0.5100, -0.0561],\n",
       "         [ 0.7500,  0.0487,  0.1738,  ...,  0.4684,  0.0030, -0.6084],\n",
       "         [ 0.0519,  0.3729,  0.5223,  ...,  0.3584,  0.6500, -0.3883]],\n",
       "\n",
       "        [[-0.2937,  0.7283, -0.1497,  ..., -0.1187, -1.0227, -0.0422],\n",
       "         [-0.2206,  0.9384, -0.0951,  ..., -0.3643, -0.6605,  0.2407],\n",
       "         [-0.1536,  0.8988, -0.0728,  ..., -0.2189, -0.8528,  0.0710],\n",
       "         ...,\n",
       "         [-0.3017,  0.9002, -0.0200,  ..., -0.1082, -0.8412, -0.0861],\n",
       "         [-0.3338,  0.9674, -0.0729,  ..., -0.1952, -0.8181, -0.0634],\n",
       "         [-0.3454,  0.8824, -0.0426,  ..., -0.0993, -0.8329, -0.1065]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ad1ab4-8c5f-4068-b177-f5f20b78c576",
   "metadata": {},
   "source": [
    "Transformers models behave like namedtuples or dictionaries. You can access the elements by attributes (like we did) or by key (`outputs[\"last_hidden_state\"]`), or even by index if you know exactly where the thing you are looking for is (`outputs[0]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ceeb1c1-765b-4fe7-ba85-205e40cd525c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 768])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to see the dimension of the output\n",
    "output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82091a34-901d-41c4-ab03-9b4dc2364def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 768])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aec7af2c-ef75-4e46-85b3-9a830299929d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 768])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251391c7-7e53-4f1e-adc9-f119a5e4789b",
   "metadata": {},
   "source": [
    "## Model heads: Making sense out of numbers\n",
    "\n",
    "The model heads take the high-dimensional vector of hidden states as input and project them onto a different dimension. They are usually composed of one or a few linear layers. The output of the Transformer model is sent directly to the model head to be processed.\n",
    "\n",
    "The embeddings layer converts each input ID in the tokenized input into a vector that represents the associated token. The subsequent layers manipulate those vectors using the attention mechanism to produce the final representation of the sentences.\n",
    "\n",
    "There are many different architectures available in 🤗 Transformers, with each one designed around tackling a specific task. Here is a non-exhaustive list:\n",
    "\n",
    "```\n",
    "    *Model (retrieve the hidden states)\n",
    "    *ForCausalLM\n",
    "    *ForMaskedLM\n",
    "    *ForMultipleChoice\n",
    "    *ForQuestionAnswering\n",
    "    *ForSequenceClassification\n",
    "    *ForTokenClassification\n",
    "```\n",
    "\n",
    "For our example, we will need a model with a `sequence classification head` (to be able to classify the sentences as positive or negative). So, we won’t actually use the AutoModel class, but `AutoModelForSequenceClassification`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6464787-76d6-4d1c-af12-64dd9dd19a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d89b33d1-5386-4692-9a1d-21dd66d5c761",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8767987c-4109-4902-9dad-73a6fc25bfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
       "          2607,  2026,  2878,  2166,  1012,   102],\n",
       "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c9929d2b-62a9-463b-b4c9-b250e560a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**token_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7eb354df-e2b7-4418-8dec-eee680b7093c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-1.5607,  1.6123],\n",
      "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "48a663b8-fbec-4d17-9153-3913d91d63df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5607,  1.6123],\n",
       "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "154c99fc-c02e-4b98-8aa1-01d8667cebb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['logits'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6719acee-e16e-4e28-8a39-abc0baf75c16",
   "metadata": {},
   "source": [
    "Since we have just two sentences and two labels, the result we get from our model is of shape 2 x 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef944b-d0af-431c-ab74-1cb500bdb7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47e29257-12fc-4d54-9216-fcc9c610a0a2",
   "metadata": {},
   "source": [
    "## Postprocessing the output\n",
    "\n",
    "The values we get as output from our model don’t necessarily make sense by themselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "53b6db24-2fc7-4c72-92ca-32ad3f857798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5607,  1.6123],\n",
      "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7304902-6aac-4cac-b4ff-1edf675c5264",
   "metadata": {},
   "source": [
    "Our model predicted `[-1.5607, 1.6123]` for the first sentence and `[ 4.1692, -3.3464]` for the second one. \n",
    "\n",
    "Those are not probabilities but `logits`, the raw, unnormalized scores outputted by the last layer of the model. \n",
    "\n",
    "To be converted to `probabilities`, they need to go through a `SoftMax` layer (all 🤗 Transformers models output the logits, as the loss function for training will generally fuse the last activation function, such as SoftMax, with the actual loss function, such as cross entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c2430e60-8f4d-4ba2-a760-832ba1734b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a1dd6449-4f25-4f9c-8966-64759aa5d309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0195e-02, 9.5981e-01],\n",
       "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = F.softmax(output.logits, dim=-1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "296f31fd-6c0d-47e3-ba03-dbf4f13e5d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_0 = F.softmax(output.logits, dim=0)\n",
    "# predictions_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2c72f91d-b7a8-4029-b01e-ff813fb229aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_1 = F.softmax(output.logits, dim=1)\n",
    "# predictions_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc99205d-3bfd-4124-8699-f423a6d752a5",
   "metadata": {},
   "source": [
    "Now we can see that the model predicted `[0.0402, 0.9598]` for the first sentence and `[0.9995, 0.0005]` for the second one. These are recognizable probability scores.\n",
    "\n",
    "To get the `labels` corresponding to each position, we can inspect the `id2label` attribute of the `model config` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "81913d59-de31-406e-b8e0-314c9f010d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3aad104e-e227-47a4-a12a-2d958dc86459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec17cf-459d-4cb3-b7a7-4d37aa817541",
   "metadata": {},
   "source": [
    "Now we can conclude that the model predicted the following:\n",
    "\n",
    "```\n",
    "First sentence: NEGATIVE: 0.0402, POSITIVE: 0.9598\n",
    "Second sentence: NEGATIVE: 0.9995, POSITIVE: 0.0005\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3868ba-84a4-40e5-9456-596ad4c7970e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b98f7a6e-1e8a-4330-ab49-bc18cead39ca",
   "metadata": {},
   "source": [
    "### Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e16d8bf4-7b9e-4c01-8f23-b82ac204d1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dc98bba-5cf7-432b-9627-750484bc15ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    \"This is an absolute joke!\",\n",
    "    \"Cristiano Ronaldo is better than Messi.\",\n",
    "    \"Life is not about only success, failure plays a vital role too.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e609752-b028-4928-b854-3b3beee8a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select checkpoint\n",
    "checkpoint = 'ProsusAI/finbert'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3d6291ef-6a0d-4573-ae04-861b69021b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22ca1f58-db2d-4a43-8271-02a385ae0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1e625adc-563b-41f5-93e7-559c5ba2663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aa08e56-d0f9-4b95-a54f-c5c7b8f8cc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2023,  2003,  2019,  7619,  8257,   999,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0],\n",
       "        [  101, 13675,  2923, 15668,  8923,  2080,  2003,  2488,  2084,  6752,\n",
       "          2072,  1012,   102,     0,     0,     0],\n",
       "        [  101,  2166,  2003,  2025,  2055,  2069,  3112,  1010,  4945,  3248,\n",
       "          1037,  8995,  2535,  2205,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_inputs = tokenizer(inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "token_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4cb48473-0542-4027-8f7d-01c1d5390f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  2023,  2003,  2019,  7619,  8257,   999,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101, 13675,  2923, 15668,  8923,  2080,  2003,  2488,  2084,  6752,\n",
      "          2072,  1012,   102,     0,     0,     0],\n",
      "        [  101,  2166,  2003,  2025,  2055,  2069,  3112,  1010,  4945,  3248,\n",
      "          1037,  8995,  2535,  2205,  1012,   102]])\n"
     ]
    }
   ],
   "source": [
    "pprint(token_inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b949c618-92de-4ac2-8759-1a22e2c575a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "pprint(token_inputs['token_type_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f24bdab5-8f87-4369-ae02-221a6feac5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "pprint(token_inputs['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4b83d327-e2a4-4c45-8a27-fcd388192254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f61a0bf4-af54-4534-bcc0-ce5a864cdd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16, 16)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_inputs['input_ids'][0]), len(token_inputs['input_ids'][1]), len(token_inputs['input_ids'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4e50d49-55f8-49be-9be1-553dcbcf5243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs from the model\n",
    "model_outputs = model(**token_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8db923a-b34e-4017-afc3-ab1182ccfc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-1.6557,  2.0578,  0.6569],\n",
       "        [ 0.9340, -2.0800,  1.0718],\n",
       "        [-1.1098, -0.2361,  1.9260]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "298b1059-f17f-45f6-b067-2ed40aa4e69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6557,  2.0578,  0.6569],\n",
       "        [ 0.9340, -2.0800,  1.0718],\n",
       "        [-1.1098, -0.2361,  1.9260]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4ce1684-5300-4511-9136-5f15c59d4f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6557,  2.0578,  0.6569],\n",
       "        [ 0.9340, -2.0800,  1.0718],\n",
       "        [-1.1098, -0.2361,  1.9260]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model_outputs.logits\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de840b15-0b32-4df5-84dd-d50d16060d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0192, 0.7869, 0.1939],\n",
       "        [0.4552, 0.0223, 0.5225],\n",
       "        [0.0413, 0.0989, 0.8598]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_probs = F.softmax(logits, dim=-1)\n",
    "output_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f6d84596-3aa1-44be-9cf5-136d0d67526f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'positive', 1: 'negative', 2: 'neutral'}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "26bb7942-a7a1-444d-9eaa-89dc3a24370c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': 0, 'negative': 1, 'neutral': 2}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "da916aa7-29ab-43ab-8554-78840f2c9f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d9234b1f-2483-43d9-9b37-79a35c0954a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_output(model, output_probs):\n",
    "    results = []\n",
    "    \n",
    "    for prob_list in output_probs:\n",
    "        prob = torch.max(prob_list)\n",
    "        ix = torch.argmax(prob_list)\n",
    "\n",
    "        if ix == torch.tensor(model.config.label2id['positive']):\n",
    "            pos = {'label': 'POSITIVE', 'score': prob.item()}\n",
    "            results.append(pos)\n",
    "\n",
    "        elif ix == torch.tensor(model.config.label2id['negative']):\n",
    "            neg = {'label': 'NEGATIVE', 'score': prob.item()}\n",
    "            results.append(neg)\n",
    "\n",
    "        elif ix == torch.tensor(model.config.label2id['neutral']):\n",
    "            neut = {'label': 'NEUTRAL', 'score': prob.item()}\n",
    "            results.append(neut)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9f8decbd-d256-4883-93ee-1edb9c98fc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.7869254350662231},\n",
       " {'label': 'NEUTRAL', 'score': 0.522458553314209},\n",
       " {'label': 'NEUTRAL', 'score': 0.8597527742385864}]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = result_output(model, output_probs)\n",
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f01d1305-c2d9-47a4-ac90-d1e10ea86ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.result_finbert import result_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adfb416c-64b4-4ddb-b46a-59925c3ac93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = result_output(model, output_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51931201-4724-43a3-a819-da6eb5d2380d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.7869254350662231},\n",
       " {'label': 'NEUTRAL', 'score': 0.522458553314209},\n",
       " {'label': 'NEUTRAL', 'score': 0.8597527742385864}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e64877-2777-4373-804f-51778d05fac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
