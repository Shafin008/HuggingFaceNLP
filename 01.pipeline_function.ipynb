{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6764569f-5a67-465e-b5c6-29c2e833ad22",
   "metadata": {},
   "source": [
    "# Pipeline function\n",
    "\n",
    "The most basic object in the 🤗 Transformers library is the `pipeline()` function. It connects a model with its necessary preprocessing and postprocessing steps, allowing us to directly input any text and get an intelligible answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d249b8-e0e9-4ff5-a74c-121cc4fce7ae",
   "metadata": {},
   "source": [
    "## Steps taken before entering pipeline\n",
    "There are three main steps involved when you pass some text to a pipeline:\n",
    "\n",
    "- The text is preprocessed into a format the model can understand.\n",
    "- The preprocessed inputs are passed to the model.\n",
    "- The predictions of the model are post-processed, so you can make sense of them.\n",
    "\n",
    "Some of the currently available pipelines are:\n",
    "- feature-extraction (get the vector representation of a text)\n",
    "- fill-mask\n",
    "- ner (named entity recognition)\n",
    "- question-answering\n",
    "- sentiment-analysis\n",
    "- summarization\n",
    "- text-generation\n",
    "- translation\n",
    "- zero-shot-classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3885acd8-09b9-442e-a0df-79d9e1515fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from pprint import pprint\n",
    "from pprint import PrettyPrinter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802852ac-3102-4536-a791-b01e275badee",
   "metadata": {},
   "source": [
    "## Sentimnet analysis pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8c25948-fa03-46f0-8df0-20920f181d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_classification.TextClassificationPipeline at 0x1689a4800>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_classifier = pipeline(task='sentiment-analysis')\n",
    "sentiment_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de8ecb8-a25d-447b-8cc0-7305fafd4673",
   "metadata": {},
   "source": [
    "By default hf uses this [sentiment-classifier-model](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f72dc75-148b-45a3-8e90-f4a6d499117a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_classifier(inputs=\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9e138fc-824a-4865-8fb1-ebac2c37974c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can even pass several sentences!\n",
    "sentiment_classifier(inputs=\n",
    "    [\"I've been waiting for a HuggingFace course my whole life.\", \n",
    "     \"I hate this so much!\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f039825-0687-461e-ae3a-c8c5833b6c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "220eb73e-7b80-4bff-b614-ccb02c270765",
   "metadata": {},
   "source": [
    "## Zero shot classification pipeline\n",
    "\n",
    "We'll tackle a more challenging task where we need to classify texts that haven’t been labelled. This is a common scenario in real-world projects because annotating text is usually time-consuming and requires domain expertise. \n",
    "\n",
    "For this use case, the zero-shot-classification pipeline is very powerful: it allows you to specify which labels to use for the classification, so you don’t have to rely on the labels of the pretrained model. \n",
    "\n",
    "You’ve already seen how the model can classify a sentence as positive or negative using those two labels — but it can also classify the text using any other set of labels you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a857ee9a-26e3-40bc-83f9-73c8ce114a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.zero_shot_classification.ZeroShotClassificationPipeline at 0x168c0f620>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_classifier = pipeline(\"zero-shot-classification\")\n",
    "zero_shot_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3498e731-6e5c-4327-b980-ff018806d50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'This is a course about the Transformers library',\n",
      " 'labels': ['education', 'electronics', 'business', 'politics'],\n",
      " 'scores': [0.6991684436798096,\n",
      "            0.17218615114688873,\n",
      "            0.09269551187753677,\n",
      "            0.0359499566257]}\n"
     ]
    }
   ],
   "source": [
    "pprint(zero_shot_classifier(sequences=\"This is a course about the Transformers library\",\n",
    "                    candidate_labels=['education', 'business', 'politics', 'electronics']), sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776184b-a16f-4a0a-be21-233279dc45d2",
   "metadata": {},
   "source": [
    "By default hf uses this [zero-shot-classifier-model](https://huggingface.co/facebook/bart-large-mnli)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb89352-bca0-47d9-9760-2f421761a390",
   "metadata": {},
   "source": [
    "## Text Generation pipeline\n",
    "\n",
    "Now let’s see how to use a pipeline to generate some text. The main idea here is that you provide a prompt and the model will auto-complete it by generating the remaining text. This is similar to the predictive text feature that is found on many phones. Text generation involves randomness, so it’s normal to get the different results everytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af5775e7-a0b1-4e07-905b-2a30de7a4711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bacd46def1a4c49acd1048e52ba6642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  21%|##1       | 115M/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5a7d309368402c89ed00514dab2f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15401f26f2aa42ea8cb8a2dd6836d376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e837cf1c0040e69cc4458a53b44cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b8e5b1435844a3b3aa9c2565682483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e968dacd29a144cfb95e4187301f72e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_generation.TextGenerationPipeline at 0x177eebfe0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generator = pipeline('text-generation')\n",
    "text_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1e7ce0d-00a8-4411-b826-8a5b632bfabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'In this course, we will teach you how to build a modular '\n",
      "                    'application in PHP. The goal is to demonstrate how you '\n",
      "                    'can build a modular web application on a variety of '\n",
      "                    'platforms including mobile devices and on the web.\\n'\n",
      "                    '\\n'\n",
      "                    'If you are new to this course, you should take a special '\n",
      "                    'interest in programming. It is not meant to be part of a '\n",
      "                    'course but in general it is about learning. You should '\n",
      "                    'find it very informative!'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(text_generator(\"In this course, we will teach you how to\", \n",
    "                      num_return_sequences=1, max_length=300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34c52070-7681-464a-9307-b50457b1b759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'In this machine learning course, we will teach you how to '\n",
      "                    'create models for machine learning at scale. We do it by '\n",
      "                    'using a mix of data with an infinite number of variables '\n",
      "                    'for visualization and to simulate model parameters. In '\n",
      "                    'this tutorial we will cover the following techniques: '\n",
      "                    '2-D, 4-D and 3-D models\\n'\n",
      "                    '\\n'\n",
      "                    '4-D and DataGrid training\\n'\n",
      "                    '\\n'\n",
      "                    'Data visualisation and classification\\n'\n",
      "                    '\\n'\n",
      "                    'Recognition based on model parameters\\n'\n",
      "                    '\\n'\n",
      "                    'Model-guided training\\n'\n",
      "                    '\\n'\n",
      "                    'The learning'},\n",
      " {'generated_text': 'In this machine learning course, we will teach you how to '\n",
      "                    'use the NLP on a wide variety of datasets. In addition, '\n",
      "                    'we will test your machine learning knowledge in an '\n",
      "                    'intelligent way, using NLP software to create and improve '\n",
      "                    'intelligent applications.\\n'\n",
      "                    '\\n'\n",
      "                    'Note: This course will be offered one day as a part of '\n",
      "                    'Coursera. The Coursera website is free for all students.'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(text_generator(\"In this machine learning course, we will teach you how to\", num_return_sequences=2, max_length=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd08fd9-3f33-4df4-80b0-5713e19c4eea",
   "metadata": {},
   "source": [
    "By default hf uses this [text-generation-model](https://huggingface.co/openai-community/gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4638182e-60b0-45c9-941c-3223c5791b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba36abc29af44b59a7ce99305c99922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9d843bea934440a9faf1e39ee4e815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3359ee9e0a5443aba20a24e245b9a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f757e492d2486da3b956d2f6639ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7393c494ae24b748250e63b4a30f2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac054b1f1154b569711b6a1c067ec7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c17c71a5f7149ecafdb987949d83ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_generation.TextGenerationPipeline at 0x380911b20>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choosing a distilled version of this model\n",
    "text_generator_dist = pipeline('text-generation', model='distilgpt2')\n",
    "text_generator_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "114b42d5-063c-4652-8c56-745b7adb0269",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'In this course, we will teach you how to get used to the '\n",
      "                    \"challenge. And just like with any course, you'll also \"\n",
      "                    'have a goal. There will definitely be times when you want '\n",
      "                    'to start to take the challenge and get a good '\n",
      "                    'understanding of what the challenge is and how you can '\n",
      "                    'make it happen.\\n'\n",
      "                    '\\n'\n",
      "                    '\\n'\n",
      "                    '\\n'\n",
      "                    'About the Course The course is designed from scratch and '\n",
      "                    'the course is presented in a non-technical format. This '\n",
      "                    'course is created using the free Coursera. It is free and '\n",
      "                    'is available in all languages and languages, and is '\n",
      "                    'designed to answer questions from students about the '\n",
      "                    'nature and application of a course.\\n'\n",
      "                    \"You'll also be able to access the entire course with the \"\n",
      "                    'right to download information from the course website.\\n'\n",
      "                    'The course contains 3 classes in the core class, which '\n",
      "                    'will help you get into each component of each class based '\n",
      "                    'on whether you want to take on a new challenge.\\n'\n",
      "                    'A basic knowledge of programming and programming as well '\n",
      "                    'as reading basic programming are available.\\n'\n",
      "                    'Each class consists of seven types: C code on the stack, '\n",
      "                    'C code on C and C code on the stack.\\n'\n",
      "                    'Each class consists of 6,000+ topics. For all the subject '\n",
      "                    'matter of the course, this course covers several topics: '\n",
      "                    'Visualization, Programming, Artificial Intelligence, '\n",
      "                    'Language Programming, JavaScript, C code, Code. The '\n",
      "                    'lectures will be designed and delivered automatically to '\n",
      "                    'the course visitors.'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(text_generator_dist(\n",
    "    \"In this course, we will teach you how to\", \n",
    "     num_return_sequences=1, max_length=300, truncation=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37166608-18ae-4eee-817d-3e69276112cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'In this machine learning course, we will teach you how to '\n",
      "                    'start programming to run your computer. These computers '\n",
      "                    'will run many simple programs and work around each'},\n",
      " {'generated_text': 'In this machine learning course, we will teach you how to '\n",
      "                    'perform real time training by generating models to '\n",
      "                    'predict various mathematical operations using Bayesian '\n",
      "                    'inference. You'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(text_generator(\n",
    "    \"In this machine learning course, we will teach you how to\", \n",
    "    num_return_sequences=2, \n",
    "    max_length=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13c3ce4-b44f-479a-a4e4-b2834b681e78",
   "metadata": {},
   "source": [
    "model link: [text-generation-model](https://huggingface.co/distilbert/distilgpt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cbd439-df34-455e-be8d-f273e9c0026d",
   "metadata": {},
   "source": [
    "## Mask filling\n",
    "The idea of this task is to fill in the blanks in a given text.\n",
    "\n",
    "The `top_k` argument controls how many possibilities you want to be displayed. Note that here the model fills in the special `<mask>` word, which is often referred to as a mask token. Other mask-filling models might have different mask tokens, so it’s always good to verify the proper mask word when exploring other models. One way to check it is by looking at the mask word used in the widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05fe0088-d6ea-4463-8177-79c4c2b632f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "unmasker = pipeline(\"fill-mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85de4412-ccbf-4a27-831d-3c548158d925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.1919846534729004,\n",
      "  'token': 30412,\n",
      "  'token_str': ' mathematical',\n",
      "  'sequence': 'This course will teach you all about mathematical models.'},\n",
      " {'score': 0.04209178313612938,\n",
      "  'token': 38163,\n",
      "  'token_str': ' computational',\n",
      "  'sequence': 'This course will teach you all about computational models.'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(unmasker(\n",
    "    \"This course will teach you all about <mask> models.\", \n",
    "    top_k=2), \n",
    "    sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96078f37-f7ca-42dc-aff5-d323ab5c038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.019951393827795982,\n",
      "  'token': 29736,\n",
      "  'token_str': ' teamwork',\n",
      "  'sequence': 'This adventure will teach you all about teamwork.'},\n",
      " {'score': 0.016802296042442322,\n",
      "  'token': 301,\n",
      "  'token_str': ' life',\n",
      "  'sequence': 'This adventure will teach you all about life.'},\n",
      " {'score': 0.014574856497347355,\n",
      "  'token': 7967,\n",
      "  'token_str': ' survival',\n",
      "  'sequence': 'This adventure will teach you all about survival.'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(unmasker(\n",
    "    \"This adventure will teach you all about <mask>.\", \n",
    "    top_k=3), \n",
    "    sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7df5780-24be-4772-a0f6-3617b1bcf021",
   "metadata": {},
   "source": [
    "hf uses this model as default for mask fill: [mask-fill-model](https://huggingface.co/distilbert/distilroberta-base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b3450c-0d55-46da-b631-db02322cf98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying a different masking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bceceb0c-a1ed-4a82-8eae-2bb970e08b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.fill_mask.FillMaskPipeline at 0x169e16b40>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker_2 = pipeline('fill-mask', model='bert-base-cased')\n",
    "unmasker_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8de6cdd6-7f2b-4bfc-a401-b44d2570e351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.2596316337585449,\n",
      "  'token': 1648,\n",
      "  'token_str': 'role',\n",
      "  'sequence': 'This course will teach you all about role models.'},\n",
      " {'score': 0.09427271783351898,\n",
      "  'token': 1103,\n",
      "  'token_str': 'the',\n",
      "  'sequence': 'This course will teach you all about the models.'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(unmasker_2(\n",
    "    \"This course will teach you all about [MASK] models.\", \n",
    "    top_k=2), \n",
    "    sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5949bb3-c190-4bfb-9304-c40ae9135d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.11905951797962189,\n",
      "  'token': 1297,\n",
      "  'token_str': 'life',\n",
      "  'sequence': 'This adventure will teach you all about life.'},\n",
      " {'score': 0.10742107033729553,\n",
      "  'token': 1122,\n",
      "  'token_str': 'it',\n",
      "  'sequence': 'This adventure will teach you all about it.'},\n",
      " {'score': 0.06707874685525894,\n",
      "  'token': 3974,\n",
      "  'token_str': 'magic',\n",
      "  'sequence': 'This adventure will teach you all about magic.'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(unmasker_2(\n",
    "    \"This adventure will teach you all about [MASK].\", \n",
    "    top_k=3), \n",
    "    sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0914fc-8562-4e1a-837a-a8ed478d5402",
   "metadata": {},
   "source": [
    "We used this model for mask-fill: [mask-fill-model](https://huggingface.co/google-bert/bert-base-cased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6bf019-9fd0-4334-9c0c-dcfda18df7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41f687a7-8a86-4e8f-a6dc-cd22987f3dda",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "Named entity recognition (NER) is a task where the model has to find which parts of the input text correspond to entities such as persons, locations, or organizations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83870056-feb1-473b-82fc-67113a8f45c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08641a46d2f94939a0f2cc3d44634c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  40%|####      | 535M/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716b928a74e34e7086a56eafdec7a3ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b1cdc38e664573a1107095d76039c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "/Users/shafinsaapel/tensorflow-test/env/lib/python3.12/site-packages/transformers/pipelines/token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", grouped_entities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e2993fe-66ac-42c2-9e12-938b4fdf84f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER',\n",
      "  'score': 0.9981694,\n",
      "  'word': 'Sylvain',\n",
      "  'start': 11,\n",
      "  'end': 18},\n",
      " {'entity_group': 'ORG',\n",
      "  'score': 0.9796019,\n",
      "  'word': 'Hugging Face',\n",
      "  'start': 33,\n",
      "  'end': 45},\n",
      " {'entity_group': 'LOC',\n",
      "  'score': 0.9932106,\n",
      "  'word': 'Brooklyn',\n",
      "  'start': 49,\n",
      "  'end': 57}]\n"
     ]
    }
   ],
   "source": [
    "pprint(ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\"), sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d56c8a1-dc51-4786-82b6-c93ee97e90fa",
   "metadata": {},
   "source": [
    "Here the model correctly identified that Sylvain is a person (PER), Hugging Face an organization (ORG), and Brooklyn a location (LOC).\n",
    "\n",
    "We pass the option grouped_entities=True in the pipeline creation function to tell the pipeline to regroup together the parts of the sentence that correspond to the same entity: here the model correctly grouped “Hugging” and “Face” as a single organization, even though the name consists of multiple words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9bb70559-e263-48b8-885d-4dd57961e184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER',\n",
      "  'score': 0.9573288,\n",
      "  'word': 'Shafin',\n",
      "  'start': 5,\n",
      "  'end': 11},\n",
      " {'entity_group': 'ORG',\n",
      "  'score': 0.90827066,\n",
      "  'word': 'CVO Petrochemical Refinery LTD',\n",
      "  'start': 19,\n",
      "  'end': 49},\n",
      " {'entity_group': 'LOC',\n",
      "  'score': 0.9988945,\n",
      "  'word': 'Chittagong',\n",
      "  'start': 53,\n",
      "  'end': 63}]\n"
     ]
    }
   ],
   "source": [
    "pprint(\n",
    "    ner(\"Hey, Shafin joined CVO Petrochemical Refinery LTD in Chittagong, he'll be working as a Mechanical Engineer.\"), \n",
    "    sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aea6cfb-82ad-4e46-a9ec-7218b3b2e9b0",
   "metadata": {},
   "source": [
    "hf uses this model by default for ner: [NER](https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3172a8-c9a6-4ce4-b2f1-99f5f7618698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d830d2ae-3a49-43aa-97b8-c71e9c730c28",
   "metadata": {},
   "source": [
    "## Question-Answering pipeline\n",
    "\n",
    "The question-answering pipeline answers questions using information from a given context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07e4cd94-0798-4dea-9cd3-bf1c15989739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27df54e5f2549acb532a3515eb65453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c5d9461d44444cbc2ce6b4bf053033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72eacd1d6dda46139ce31e34675b9329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8566ae1e4c346478a1a3af826b90a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fd253ea0534f34812a60d6ef0735dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f48dc2ab-4d97-4bd3-bed7-94b63786866f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.6949763894081116, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}\n"
     ]
    }
   ],
   "source": [
    "pprint(\n",
    "    question_answerer(\n",
    "        question=\"Where do I work?\",\n",
    "        context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
    "    ), sort_dicts=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf970393-a5e7-42c7-aa8a-ca3d032f22b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9580652117729187,\n",
      " 'start': 87,\n",
      " 'end': 106,\n",
      " 'answer': 'Mechanical Engineer'}\n"
     ]
    }
   ],
   "source": [
    "pprint(\n",
    "    question_answerer(\n",
    "        question=\"Which position in the job Shafin currently working?\",\n",
    "        context=\"Hey, Shafin joined CVO Petrochemical Refinery LTD in Chittagong, he'll be working as a Mechanical Engineer.\",\n",
    "    ), sort_dicts=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f605ae3f-10a3-4cce-baf3-adee0bc8ef37",
   "metadata": {},
   "source": [
    "hf use this model by default: [QA model](https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6038298-b0a1-4562-bb67-ae4fa46a3544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90618e2a-2c40-4cc3-971d-20645ea4ca1c",
   "metadata": {},
   "source": [
    "## Text Summarization\n",
    "Summarization is the task of reducing a text into a shorter text while keeping all (or most) of the important aspects referenced in the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fd8ae7b-1855-48ed-8ff5-e77a710bfd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf517bc6c6e4b56b2297b6167178c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07409fe866642c69e02312056ed902c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79b67c06c2b4e5eaf75ce236a409c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1acff05403e74b7c97310f87ea8d74ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef19c861016349b08dcc9283aa646e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70da1db5177940b48db1beb25fbb7361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "387647cd-5b30-4605-a890-d6d7503b106f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' America has changed dramatically during recent years . The '\n",
      "                  'number of engineering graduates in the U.S. has declined in '\n",
      "                  'traditional engineering disciplines such as mechanical, '\n",
      "                  'civil,    electrical, chemical, and aeronautical '\n",
      "                  'engineering . Rapidly developing economies such as China '\n",
      "                  'and India continue to encourage and advance the teaching of '\n",
      "                  'engineering .'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(\n",
    "    summarizer(\n",
    "    \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b541682-2a68-428b-9ea7-b2125dbe9656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1df1cf75-6b07-4362-8e1b-4909ab62a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarizer_2 = pipeline('summarization', model='facebook/bart-large-cnn')\n",
    "# summarizer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ffeb3d-7370-4933-a7a4-63aa3cc7ecaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9611b4d4-7e08-4dbe-b807-9791bd91c042",
   "metadata": {},
   "source": [
    "## Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bcfa73c-8d37-4b0d-abd1-f04d02c0d3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2690c478914fc9866db2dc3a0e0a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f565dca052a4e269ad3312d33795cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1226dba538344d8fa6139f86f1d2f3fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daca4222a07d4dfb8822c235f16a2d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22cd7c6bddc40648149c27ced5bc6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977c11e3a9784a2eab7e03527b0ab0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80ebd56f96e46e5abbebea421e78c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29fea54986944a59c6a12569cab32b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5f6a332a-b024-42a8-8036-8d32f609e289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'This course is produced by Hugging Face.'}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(\"Ce cours est produit par Hugging Face.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38bf4b-6059-46ec-a367-a218ae2e8bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "866a92eb-4801-4d67-b9b8-0d591bf82875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translator_2 = pipeline(\"translation\", model=\"google-t5/t5-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005523ff-03f7-47ed-9611-7f61b59b35ed",
   "metadata": {},
   "source": [
    "## Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f3882fc-1356-460c-85a9-51cf21ddf468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.06232520937919617,\n",
       "  'token': 4545,\n",
       "  'token_str': 'lawyer',\n",
       "  'sequence': 'This man works as a lawyer.'},\n",
       " {'score': 0.04933382198214531,\n",
       "  'token': 25169,\n",
       "  'token_str': 'carpenter',\n",
       "  'sequence': 'This man works as a carpenter.'},\n",
       " {'score': 0.047737520188093185,\n",
       "  'token': 3995,\n",
       "  'token_str': 'doctor',\n",
       "  'sequence': 'This man works as a doctor.'},\n",
       " {'score': 0.044364992529153824,\n",
       "  'token': 17989,\n",
       "  'token_str': 'waiter',\n",
       "  'sequence': 'This man works as a waiter.'},\n",
       " {'score': 0.037364307790994644,\n",
       "  'token': 19459,\n",
       "  'token_str': 'mechanic',\n",
       "  'sequence': 'This man works as a mechanic.'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = unmasker_2(\"This man works as a [MASK].\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6814d25f-4b43-4bae-831c-8177eb70f36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lawyer', 'carpenter', 'doctor', 'waiter', 'mechanic']\n"
     ]
    }
   ],
   "source": [
    "print([r['token_str'] for r in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d1e9437-9f14-49c9-86a6-a0f24304b3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.1565699726343155,\n",
       "  'token': 7439,\n",
       "  'token_str': 'nurse',\n",
       "  'sequence': 'This woman works as a nurse.'},\n",
       " {'score': 0.07848469167947769,\n",
       "  'token': 15098,\n",
       "  'token_str': 'waitress',\n",
       "  'sequence': 'This woman works as a waitress.'},\n",
       " {'score': 0.06936608254909515,\n",
       "  'token': 3218,\n",
       "  'token_str': 'teacher',\n",
       "  'sequence': 'This woman works as a teacher.'},\n",
       " {'score': 0.06558685749769211,\n",
       "  'token': 13487,\n",
       "  'token_str': 'maid',\n",
       "  'sequence': 'This woman works as a maid.'},\n",
       " {'score': 0.05474084988236427,\n",
       "  'token': 21803,\n",
       "  'token_str': 'prostitute',\n",
       "  'sequence': 'This woman works as a prostitute.'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = unmasker_2(\"This woman works as a [MASK].\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6db06b92-6d76-4f00-b2b2-9bca97e03f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nurse', 'waitress', 'teacher', 'maid', 'prostitute']\n"
     ]
    }
   ],
   "source": [
    "print([r['token_str'] for r in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12277aa9-2922-42f6-bb71-b67a065563b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.06863328814506531,\n",
       "  'token': 3218,\n",
       "  'token_str': 'teacher',\n",
       "  'sequence': 'This person works as a teacher.'},\n",
       " {'score': 0.03270767256617546,\n",
       "  'token': 7439,\n",
       "  'token_str': 'nurse',\n",
       "  'sequence': 'This person works as a nurse.'},\n",
       " {'score': 0.024906069040298462,\n",
       "  'token': 4545,\n",
       "  'token_str': 'lawyer',\n",
       "  'sequence': 'This person works as a lawyer.'},\n",
       " {'score': 0.024833444505929947,\n",
       "  'token': 3995,\n",
       "  'token_str': 'doctor',\n",
       "  'sequence': 'This person works as a doctor.'},\n",
       " {'score': 0.021647684276103973,\n",
       "  'token': 17989,\n",
       "  'token_str': 'waiter',\n",
       "  'sequence': 'This person works as a waiter.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = unmasker_2(\"This person works as a [MASK].\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d28f82d8-e5c7-491a-9657-e10043c34d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['teacher', 'nurse', 'lawyer', 'doctor', 'waiter']\n"
     ]
    }
   ],
   "source": [
    "print([r['token_str'] for r in result])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ccfad4-04f3-49e6-9a92-13ecfc073948",
   "metadata": {},
   "source": [
    "# How to use HF inference\n",
    "\n",
    "1. Go to the Hugging Face Model Hub\n",
    "    - Visit Hugging Face Models.\n",
    "    - Use the search bar to find a model (e.g., \"GPT-2,\" \"Whisper,\" \"Stable Diffusion\").\n",
    "      \n",
    "\n",
    "2. Select a Model\n",
    "    - Click on a model to open its page.\n",
    "    - Popular models have a built-in \"Inference API\" tab or \"Widget\" for quick testing.\n",
    "      \n",
    "\n",
    "3. Use the Inference API Widget\n",
    "\n",
    "    - Many models have a text box or upload option where you can enter input (e.g., type text for a text model, upload an image for a vision model).\n",
    "    - Click \"Run\" to generate the output.\n",
    "\n",
    "\n",
    "4. Use the Hosted Inference API (Optional, for Developers)\n",
    "\n",
    "    - You can copy the Inference API code snippet in Python or cURL from the model page to use in your own projects. Example for text generation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fce529fc-f1de-45bb-ab38-2e6b05c2379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests  \n",
    "\n",
    "# API_URL = \"https://api-inference.huggingface.co/models/gpt2\"\n",
    "# headers = {\"Authorization\": f\"Bearer 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\"}\n",
    "\n",
    "# payload = {\"inputs\": \"I'm fine\"}\n",
    "# response = requests.post(API_URL, headers=headers, json=payload)\n",
    "\n",
    "# print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ddff4-b8b7-41d3-b1fa-a8c2475b3658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
