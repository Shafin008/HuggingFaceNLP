{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6764569f-5a67-465e-b5c6-29c2e833ad22",
   "metadata": {},
   "source": [
    "# Pipeline function\n",
    "\n",
    "The most basic object in the ðŸ¤— Transformers library is the `pipeline()` function. It connects a model with its necessary preprocessing and postprocessing steps, allowing us to directly input any text and get an intelligible answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d249b8-e0e9-4ff5-a74c-121cc4fce7ae",
   "metadata": {},
   "source": [
    "## Steps taken before entering pipeline\n",
    "There are three main steps involved when you pass some text to a pipeline:\n",
    "\n",
    "- The text is preprocessed into a format the model can understand.\n",
    "- The preprocessed inputs are passed to the model.\n",
    "- The predictions of the model are post-processed, so you can make sense of them.\n",
    "\n",
    "Some of the currently available pipelines are:\n",
    "- feature-extraction (get the vector representation of a text)\n",
    "- fill-mask\n",
    "- ner (named entity recognition)\n",
    "- question-answering\n",
    "- sentiment-analysis\n",
    "- summarization\n",
    "- text-generation\n",
    "- translation\n",
    "- zero-shot-classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3885acd8-09b9-442e-a0df-79d9e1515fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from pprint import pprint\n",
    "from pprint import PrettyPrinter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802852ac-3102-4536-a791-b01e275badee",
   "metadata": {},
   "source": [
    "## Sentimnet analysis pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8c25948-fa03-46f0-8df0-20920f181d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_classification.TextClassificationPipeline at 0x1689a4800>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_classifier = pipeline(task='sentiment-analysis')\n",
    "sentiment_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de8ecb8-a25d-447b-8cc0-7305fafd4673",
   "metadata": {},
   "source": [
    "By default hf uses this [sentiment-classifier-model](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f72dc75-148b-45a3-8e90-f4a6d499117a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_classifier(inputs=\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9e138fc-824a-4865-8fb1-ebac2c37974c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can even pass several sentences!\n",
    "sentiment_classifier(inputs=\n",
    "    [\"I've been waiting for a HuggingFace course my whole life.\", \n",
    "     \"I hate this so much!\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f039825-0687-461e-ae3a-c8c5833b6c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "220eb73e-7b80-4bff-b614-ccb02c270765",
   "metadata": {},
   "source": [
    "## Zero shot classification pipeline\n",
    "\n",
    "We'll tackle a more challenging task where we need to classify texts that havenâ€™t been labelled. This is a common scenario in real-world projects because annotating text is usually time-consuming and requires domain expertise. \n",
    "\n",
    "For this use case, the zero-shot-classification pipeline is very powerful: it allows you to specify which labels to use for the classification, so you donâ€™t have to rely on the labels of the pretrained model. \n",
    "\n",
    "Youâ€™ve already seen how the model can classify a sentence as positive or negative using those two labels â€” but it can also classify the text using any other set of labels you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a857ee9a-26e3-40bc-83f9-73c8ce114a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.zero_shot_classification.ZeroShotClassificationPipeline at 0x168c0f620>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_classifier = pipeline(\"zero-shot-classification\")\n",
    "zero_shot_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3498e731-6e5c-4327-b980-ff018806d50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'This is a course about the Transformers library',\n",
      " 'labels': ['education', 'electronics', 'business', 'politics'],\n",
      " 'scores': [0.6991684436798096,\n",
      "            0.17218615114688873,\n",
      "            0.09269551187753677,\n",
      "            0.0359499566257]}\n"
     ]
    }
   ],
   "source": [
    "pprint(zero_shot_classifier(sequences=\"This is a course about the Transformers library\",\n",
    "                    candidate_labels=['education', 'business', 'politics', 'electronics']), sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776184b-a16f-4a0a-be21-233279dc45d2",
   "metadata": {},
   "source": [
    "By default hf uses this [zero-shot-classifier-model](https://huggingface.co/facebook/bart-large-mnli)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb89352-bca0-47d9-9760-2f421761a390",
   "metadata": {},
   "source": [
    "## Text Generation pipeline\n",
    "\n",
    "Now letâ€™s see how to use a pipeline to generate some text. The main idea here is that you provide a prompt and the model will auto-complete it by generating the remaining text. This is similar to the predictive text feature that is found on many phones. Text generation involves randomness, so itâ€™s normal to get the different results everytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af5775e7-a0b1-4e07-905b-2a30de7a4711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bacd46def1a4c49acd1048e52ba6642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  21%|##1       | 115M/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5a7d309368402c89ed00514dab2f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15401f26f2aa42ea8cb8a2dd6836d376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e837cf1c0040e69cc4458a53b44cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b8e5b1435844a3b3aa9c2565682483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e968dacd29a144cfb95e4187301f72e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_generation.TextGenerationPipeline at 0x177eebfe0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generator = pipeline('text-generation')\n",
    "text_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1e7ce0d-00a8-4411-b826-8a5b632bfabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'In this course, we will teach you how to build a modular '\n",
      "                    'application in PHP. The goal is to demonstrate how you '\n",
      "                    'can build a modular web application on a variety of '\n",
      "                    'platforms including mobile devices and on the web.\\n'\n",
      "                    '\\n'\n",
      "                    'If you are new to this course, you should take a special '\n",
      "                    'interest in programming. It is not meant to be part of a '\n",
      "                    'course but in general it is about learning. You should '\n",
      "                    'find it very informative!'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(text_generator(\"In this course, we will teach you how to\", \n",
    "                      num_return_sequences=1, max_length=300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34c52070-7681-464a-9307-b50457b1b759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'In this machine learning course, we will teach you how to '\n",
      "                    'create models for machine learning at scale. We do it by '\n",
      "                    'using a mix of data with an infinite number of variables '\n",
      "                    'for visualization and to simulate model parameters. In '\n",
      "                    'this tutorial we will cover the following techniques: '\n",
      "                    '2-D, 4-D and 3-D models\\n'\n",
      "                    '\\n'\n",
      "                    '4-D and DataGrid training\\n'\n",
      "                    '\\n'\n",
      "                    'Data visualisation and classification\\n'\n",
      "                    '\\n'\n",
      "                    'Recognition based on model parameters\\n'\n",
      "                    '\\n'\n",
      "                    'Model-guided training\\n'\n",
      "                    '\\n'\n",
      "                    'The learning'},\n",
      " {'generated_text': 'In this machine learning course, we will teach you how to '\n",
      "                    'use the NLP on a wide variety of datasets. In addition, '\n",
      "                    'we will test your machine learning knowledge in an '\n",
      "                    'intelligent way, using NLP software to create and improve '\n",
      "                    'intelligent applications.\\n'\n",
      "                    '\\n'\n",
      "                    'Note: This course will be offered one day as a part of '\n",
      "                    'Coursera. The Coursera website is free for all students.'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(text_generator(\"In this machine learning course, we will teach you how to\", num_return_sequences=2, max_length=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd08fd9-3f33-4df4-80b0-5713e19c4eea",
   "metadata": {},
   "source": [
    "By default hf uses this [text-generation-model](https://huggingface.co/openai-community/gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4638182e-60b0-45c9-941c-3223c5791b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba36abc29af44b59a7ce99305c99922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9d843bea934440a9faf1e39ee4e815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3359ee9e0a5443aba20a24e245b9a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f757e492d2486da3b956d2f6639ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7393c494ae24b748250e63b4a30f2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac054b1f1154b569711b6a1c067ec7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c17c71a5f7149ecafdb987949d83ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_generation.TextGenerationPipeline at 0x380911b20>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choosing a distilled version of this model\n",
    "text_generator_dist = pipeline('text-generation', model='distilgpt2')\n",
    "text_generator_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "114b42d5-063c-4652-8c56-745b7adb0269",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'In this course, we will teach you how to get used to the '\n",
      "                    \"challenge. And just like with any course, you'll also \"\n",
      "                    'have a goal. There will definitely be times when you want '\n",
      "                    'to start to take the challenge and get a good '\n",
      "                    'understanding of what the challenge is and how you can '\n",
      "                    'make it happen.\\n'\n",
      "                    '\\n'\n",
      "                    '\\n'\n",
      "                    '\\n'\n",
      "                    'About the Course The course is designed from scratch and '\n",
      "                    'the course is presented in a non-technical format. This '\n",
      "                    'course is created using the free Coursera. It is free and '\n",
      "                    'is available in all languages and languages, and is '\n",
      "                    'designed to answer questions from students about the '\n",
      "                    'nature and application of a course.\\n'\n",
      "                    \"You'll also be able to access the entire course with the \"\n",
      "                    'right to download information from the course website.\\n'\n",
      "                    'The course contains 3 classes in the core class, which '\n",
      "                    'will help you get into each component of each class based '\n",
      "                    'on whether you want to take on a new challenge.\\n'\n",
      "                    'A basic knowledge of programming and programming as well '\n",
      "                    'as reading basic programming are available.\\n'\n",
      "                    'Each class consists of seven types: C code on the stack, '\n",
      "                    'C code on C and C code on the stack.\\n'\n",
      "                    'Each class consists of 6,000+ topics. For all the subject '\n",
      "                    'matter of the course, this course covers several topics: '\n",
      "                    'Visualization, Programming, Artificial Intelligence, '\n",
      "                    'Language Programming, JavaScript, C code, Code. The '\n",
      "                    'lectures will be designed and delivered automatically to '\n",
      "                    'the course visitors.'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(text_generator_dist(\n",
    "    \"In this course, we will teach you how to\", \n",
    "     num_return_sequences=1, max_length=300, truncation=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37166608-18ae-4eee-817d-3e69276112cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'In this machine learning course, we will teach you how to '\n",
      "                    'start programming to run your computer. These computers '\n",
      "                    'will run many simple programs and work around each'},\n",
      " {'generated_text': 'In this machine learning course, we will teach you how to '\n",
      "                    'perform real time training by generating models to '\n",
      "                    'predict various mathematical operations using Bayesian '\n",
      "                    'inference. You'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(text_generator(\n",
    "    \"In this machine learning course, we will teach you how to\", \n",
    "    num_return_sequences=2, \n",
    "    max_length=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13c3ce4-b44f-479a-a4e4-b2834b681e78",
   "metadata": {},
   "source": [
    "model link: [text-generation-model](https://huggingface.co/distilbert/distilgpt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cbd439-df34-455e-be8d-f273e9c0026d",
   "metadata": {},
   "source": [
    "## Mask filling\n",
    "The idea of this task is to fill in the blanks in a given text.\n",
    "\n",
    "The `top_k` argument controls how many possibilities you want to be displayed. Note that here the model fills in the special `<mask>` word, which is often referred to as a mask token. Other mask-filling models might have different mask tokens, so itâ€™s always good to verify the proper mask word when exploring other models. One way to check it is by looking at the mask word used in the widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05fe0088-d6ea-4463-8177-79c4c2b632f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "unmasker = pipeline(\"fill-mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85de4412-ccbf-4a27-831d-3c548158d925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.1919846534729004,\n",
      "  'token': 30412,\n",
      "  'token_str': ' mathematical',\n",
      "  'sequence': 'This course will teach you all about mathematical models.'},\n",
      " {'score': 0.04209178313612938,\n",
      "  'token': 38163,\n",
      "  'token_str': ' computational',\n",
      "  'sequence': 'This course will teach you all about computational models.'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(unmasker(\n",
    "    \"This course will teach you all about <mask> models.\", \n",
    "    top_k=2), \n",
    "    sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96078f37-f7ca-42dc-aff5-d323ab5c038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.019951393827795982,\n",
      "  'token': 29736,\n",
      "  'token_str': ' teamwork',\n",
      "  'sequence': 'This adventure will teach you all about teamwork.'},\n",
      " {'score': 0.016802296042442322,\n",
      "  'token': 301,\n",
      "  'token_str': ' life',\n",
      "  'sequence': 'This adventure will teach you all about life.'},\n",
      " {'score': 0.014574856497347355,\n",
      "  'token': 7967,\n",
      "  'token_str': ' survival',\n",
      "  'sequence': 'This adventure will teach you all about survival.'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(unmasker(\n",
    "    \"This adventure will teach you all about <mask>.\", \n",
    "    top_k=3), \n",
    "    sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7df5780-24be-4772-a0f6-3617b1bcf021",
   "metadata": {},
   "source": [
    "hf uses this model as default for mask fill: [mask-fill-model](https://huggingface.co/distilbert/distilroberta-base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b3450c-0d55-46da-b631-db02322cf98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying a different masking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bceceb0c-a1ed-4a82-8eae-2bb970e08b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.fill_mask.FillMaskPipeline at 0x169e16b40>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker_2 = pipeline('fill-mask', model='bert-base-cased')\n",
    "unmasker_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8de6cdd6-7f2b-4bfc-a401-b44d2570e351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.2596316337585449,\n",
      "  'token': 1648,\n",
      "  'token_str': 'role',\n",
      "  'sequence': 'This course will teach you all about role models.'},\n",
      " {'score': 0.09427271783351898,\n",
      "  'token': 1103,\n",
      "  'token_str': 'the',\n",
      "  'sequence': 'This course will teach you all about the models.'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(unmasker_2(\n",
    "    \"This course will teach you all about [MASK] models.\", \n",
    "    top_k=2), \n",
    "    sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5949bb3-c190-4bfb-9304-c40ae9135d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.11905951797962189,\n",
      "  'token': 1297,\n",
      "  'token_str': 'life',\n",
      "  'sequence': 'This adventure will teach you all about life.'},\n",
      " {'score': 0.10742107033729553,\n",
      "  'token': 1122,\n",
      "  'token_str': 'it',\n",
      "  'sequence': 'This adventure will teach you all about it.'},\n",
      " {'score': 0.06707874685525894,\n",
      "  'token': 3974,\n",
      "  'token_str': 'magic',\n",
      "  'sequence': 'This adventure will teach you all about magic.'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(unmasker_2(\n",
    "    \"This adventure will teach you all about [MASK].\", \n",
    "    top_k=3), \n",
    "    sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0914fc-8562-4e1a-837a-a8ed478d5402",
   "metadata": {},
   "source": [
    "We used this model for mask-fill: [mask-fill-model](https://huggingface.co/google-bert/bert-base-cased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6bf019-9fd0-4334-9c0c-dcfda18df7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41f687a7-8a86-4e8f-a6dc-cd22987f3dda",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "Named entity recognition (NER) is a task where the model has to find which parts of the input text correspond to entities such as persons, locations, or organizations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83870056-feb1-473b-82fc-67113a8f45c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08641a46d2f94939a0f2cc3d44634c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  40%|####      | 535M/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716b928a74e34e7086a56eafdec7a3ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b1cdc38e664573a1107095d76039c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "/Users/shafinsaapel/tensorflow-test/env/lib/python3.12/site-packages/transformers/pipelines/token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", grouped_entities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e2993fe-66ac-42c2-9e12-938b4fdf84f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER',\n",
      "  'score': 0.9981694,\n",
      "  'word': 'Sylvain',\n",
      "  'start': 11,\n",
      "  'end': 18},\n",
      " {'entity_group': 'ORG',\n",
      "  'score': 0.9796019,\n",
      "  'word': 'Hugging Face',\n",
      "  'start': 33,\n",
      "  'end': 45},\n",
      " {'entity_group': 'LOC',\n",
      "  'score': 0.9932106,\n",
      "  'word': 'Brooklyn',\n",
      "  'start': 49,\n",
      "  'end': 57}]\n"
     ]
    }
   ],
   "source": [
    "pprint(ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\"), sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d56c8a1-dc51-4786-82b6-c93ee97e90fa",
   "metadata": {},
   "source": [
    "Here the model correctly identified that Sylvain is a person (PER), Hugging Face an organization (ORG), and Brooklyn a location (LOC).\n",
    "\n",
    "We pass the option grouped_entities=True in the pipeline creation function to tell the pipeline to regroup together the parts of the sentence that correspond to the same entity: here the model correctly grouped â€œHuggingâ€ and â€œFaceâ€ as a single organization, even though the name consists of multiple words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9bb70559-e263-48b8-885d-4dd57961e184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER',\n",
      "  'score': 0.9573288,\n",
      "  'word': 'Shafin',\n",
      "  'start': 5,\n",
      "  'end': 11},\n",
      " {'entity_group': 'ORG',\n",
      "  'score': 0.90827066,\n",
      "  'word': 'CVO Petrochemical Refinery LTD',\n",
      "  'start': 19,\n",
      "  'end': 49},\n",
      " {'entity_group': 'LOC',\n",
      "  'score': 0.9988945,\n",
      "  'word': 'Chittagong',\n",
      "  'start': 53,\n",
      "  'end': 63}]\n"
     ]
    }
   ],
   "source": [
    "pprint(\n",
    "    ner(\"Hey, Shafin joined CVO Petrochemical Refinery LTD in Chittagong, he'll be working as a Mechanical Engineer.\"), \n",
    "    sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aea6cfb-82ad-4e46-a9ec-7218b3b2e9b0",
   "metadata": {},
   "source": [
    "hf uses this model by default for ner: [NER](https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3172a8-c9a6-4ce4-b2f1-99f5f7618698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d830d2ae-3a49-43aa-97b8-c71e9c730c28",
   "metadata": {},
   "source": [
    "## Question-Answering pipeline\n",
    "\n",
    "The question-answering pipeline answers questions using information from a given context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07e4cd94-0798-4dea-9cd3-bf1c15989739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27df54e5f2549acb532a3515eb65453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c5d9461d44444cbc2ce6b4bf053033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72eacd1d6dda46139ce31e34675b9329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8566ae1e4c346478a1a3af826b90a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fd253ea0534f34812a60d6ef0735dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f48dc2ab-4d97-4bd3-bed7-94b63786866f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.6949763894081116, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}\n"
     ]
    }
   ],
   "source": [
    "pprint(\n",
    "    question_answerer(\n",
    "        question=\"Where do I work?\",\n",
    "        context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
    "    ), sort_dicts=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf970393-a5e7-42c7-aa8a-ca3d032f22b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9580652117729187,\n",
      " 'start': 87,\n",
      " 'end': 106,\n",
      " 'answer': 'Mechanical Engineer'}\n"
     ]
    }
   ],
   "source": [
    "pprint(\n",
    "    question_answerer(\n",
    "        question=\"Which position in the job Shafin currently working?\",\n",
    "        context=\"Hey, Shafin joined CVO Petrochemical Refinery LTD in Chittagong, he'll be working as a Mechanical Engineer.\",\n",
    "    ), sort_dicts=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f605ae3f-10a3-4cce-baf3-adee0bc8ef37",
   "metadata": {},
   "source": [
    "hf use this model by default: [QA model](https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6038298-b0a1-4562-bb67-ae4fa46a3544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90618e2a-2c40-4cc3-971d-20645ea4ca1c",
   "metadata": {},
   "source": [
    "## Text Summarization\n",
    "Summarization is the task of reducing a text into a shorter text while keeping all (or most) of the important aspects referenced in the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fd8ae7b-1855-48ed-8ff5-e77a710bfd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf517bc6c6e4b56b2297b6167178c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07409fe866642c69e02312056ed902c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79b67c06c2b4e5eaf75ce236a409c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1acff05403e74b7c97310f87ea8d74ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef19c861016349b08dcc9283aa646e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70da1db5177940b48db1beb25fbb7361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "387647cd-5b30-4605-a890-d6d7503b106f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' America has changed dramatically during recent years . The '\n",
      "                  'number of engineering graduates in the U.S. has declined in '\n",
      "                  'traditional engineering disciplines such as mechanical, '\n",
      "                  'civil,    electrical, chemical, and aeronautical '\n",
      "                  'engineering . Rapidly developing economies such as China '\n",
      "                  'and India continue to encourage and advance the teaching of '\n",
      "                  'engineering .'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(\n",
    "    summarizer(\n",
    "    \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b541682-2a68-428b-9ea7-b2125dbe9656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1df1cf75-6b07-4362-8e1b-4909ab62a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarizer_2 = pipeline('summarization', model='facebook/bart-large-cnn')\n",
    "# summarizer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ffeb3d-7370-4933-a7a4-63aa3cc7ecaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9611b4d4-7e08-4dbe-b807-9791bd91c042",
   "metadata": {},
   "source": [
    "## Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bcfa73c-8d37-4b0d-abd1-f04d02c0d3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2690c478914fc9866db2dc3a0e0a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f565dca052a4e269ad3312d33795cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1226dba538344d8fa6139f86f1d2f3fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daca4222a07d4dfb8822c235f16a2d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22cd7c6bddc40648149c27ced5bc6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977c11e3a9784a2eab7e03527b0ab0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80ebd56f96e46e5abbebea421e78c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29fea54986944a59c6a12569cab32b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5f6a332a-b024-42a8-8036-8d32f609e289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'This course is produced by Hugging Face.'}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(\"Ce cours est produit par Hugging Face.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38bf4b-6059-46ec-a367-a218ae2e8bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "866a92eb-4801-4d67-b9b8-0d591bf82875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translator_2 = pipeline(\"translation\", model=\"google-t5/t5-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005523ff-03f7-47ed-9611-7f61b59b35ed",
   "metadata": {},
   "source": [
    "## Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f3882fc-1356-460c-85a9-51cf21ddf468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.06232520937919617,\n",
       "  'token': 4545,\n",
       "  'token_str': 'lawyer',\n",
       "  'sequence': 'This man works as a lawyer.'},\n",
       " {'score': 0.04933382198214531,\n",
       "  'token': 25169,\n",
       "  'token_str': 'carpenter',\n",
       "  'sequence': 'This man works as a carpenter.'},\n",
       " {'score': 0.047737520188093185,\n",
       "  'token': 3995,\n",
       "  'token_str': 'doctor',\n",
       "  'sequence': 'This man works as a doctor.'},\n",
       " {'score': 0.044364992529153824,\n",
       "  'token': 17989,\n",
       "  'token_str': 'waiter',\n",
       "  'sequence': 'This man works as a waiter.'},\n",
       " {'score': 0.037364307790994644,\n",
       "  'token': 19459,\n",
       "  'token_str': 'mechanic',\n",
       "  'sequence': 'This man works as a mechanic.'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = unmasker_2(\"This man works as a [MASK].\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6814d25f-4b43-4bae-831c-8177eb70f36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lawyer', 'carpenter', 'doctor', 'waiter', 'mechanic']\n"
     ]
    }
   ],
   "source": [
    "print([r['token_str'] for r in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d1e9437-9f14-49c9-86a6-a0f24304b3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.1565699726343155,\n",
       "  'token': 7439,\n",
       "  'token_str': 'nurse',\n",
       "  'sequence': 'This woman works as a nurse.'},\n",
       " {'score': 0.07848469167947769,\n",
       "  'token': 15098,\n",
       "  'token_str': 'waitress',\n",
       "  'sequence': 'This woman works as a waitress.'},\n",
       " {'score': 0.06936608254909515,\n",
       "  'token': 3218,\n",
       "  'token_str': 'teacher',\n",
       "  'sequence': 'This woman works as a teacher.'},\n",
       " {'score': 0.06558685749769211,\n",
       "  'token': 13487,\n",
       "  'token_str': 'maid',\n",
       "  'sequence': 'This woman works as a maid.'},\n",
       " {'score': 0.05474084988236427,\n",
       "  'token': 21803,\n",
       "  'token_str': 'prostitute',\n",
       "  'sequence': 'This woman works as a prostitute.'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = unmasker_2(\"This woman works as a [MASK].\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6db06b92-6d76-4f00-b2b2-9bca97e03f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nurse', 'waitress', 'teacher', 'maid', 'prostitute']\n"
     ]
    }
   ],
   "source": [
    "print([r['token_str'] for r in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12277aa9-2922-42f6-bb71-b67a065563b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.06863328814506531,\n",
       "  'token': 3218,\n",
       "  'token_str': 'teacher',\n",
       "  'sequence': 'This person works as a teacher.'},\n",
       " {'score': 0.03270767256617546,\n",
       "  'token': 7439,\n",
       "  'token_str': 'nurse',\n",
       "  'sequence': 'This person works as a nurse.'},\n",
       " {'score': 0.024906069040298462,\n",
       "  'token': 4545,\n",
       "  'token_str': 'lawyer',\n",
       "  'sequence': 'This person works as a lawyer.'},\n",
       " {'score': 0.024833444505929947,\n",
       "  'token': 3995,\n",
       "  'token_str': 'doctor',\n",
       "  'sequence': 'This person works as a doctor.'},\n",
       " {'score': 0.021647684276103973,\n",
       "  'token': 17989,\n",
       "  'token_str': 'waiter',\n",
       "  'sequence': 'This person works as a waiter.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = unmasker_2(\"This person works as a [MASK].\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d28f82d8-e5c7-491a-9657-e10043c34d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['teacher', 'nurse', 'lawyer', 'doctor', 'waiter']\n"
     ]
    }
   ],
   "source": [
    "print([r['token_str'] for r in result])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ccfad4-04f3-49e6-9a92-13ecfc073948",
   "metadata": {},
   "source": [
    "# How to use HF inference\n",
    "\n",
    "1. Go to the Hugging Face Model Hub\n",
    "    - Visit Hugging Face Models.\n",
    "    - Use the search bar to find a model (e.g., \"GPT-2,\" \"Whisper,\" \"Stable Diffusion\").\n",
    "      \n",
    "\n",
    "2. Select a Model\n",
    "    - Click on a model to open its page.\n",
    "    - Popular models have a built-in \"Inference API\" tab or \"Widget\" for quick testing.\n",
    "      \n",
    "\n",
    "3. Use the Inference API Widget\n",
    "\n",
    "    - Many models have a text box or upload option where you can enter input (e.g., type text for a text model, upload an image for a vision model).\n",
    "    - Click \"Run\" to generate the output.\n",
    "\n",
    "\n",
    "4. Use the Hosted Inference API (Optional, for Developers)\n",
    "\n",
    "    - You can copy the Inference API code snippet in Python or cURL from the model page to use in your own projects. Example for text generation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fce529fc-f1de-45bb-ab38-2e6b05c2379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests  \n",
    "\n",
    "# API_URL = \"https://api-inference.huggingface.co/models/gpt2\"\n",
    "# headers = {\"Authorization\": f\"Bearer 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\"}\n",
    "\n",
    "# payload = {\"inputs\": \"I'm fine\"}\n",
    "# response = requests.post(API_URL, headers=headers, json=payload)\n",
    "\n",
    "# print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ddff4-b8b7-41d3-b1fa-a8c2475b3658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
